{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQNGMaeNILDWCeEIBpYYGQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cojocarucosmin/Optimizers/blob/main/AI_Logistics_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **AI Logistics Price Prediction Model**"
      ],
      "metadata": {
        "id": "ONA_Y93Db9lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q shap gradio matplotlib numpy pandas scikit-learn"
      ],
      "metadata": {
        "id": "wxLoXeYC5xZc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistics Price AI  ·  lightweight two-tab demo\n",
        "import gradio as gr, pandas as pd, numpy as np, shap, tempfile, matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# ───────────── helpers ──────────────\n",
        "def meta_map_from_csv(meta_file):\n",
        "    if meta_file is None:\n",
        "        return {}\n",
        "    m = pd.read_csv(meta_file.name).fillna(\"\")\n",
        "    m[\"label\"] = m[\"section\"] + \" | \" + m[\"column\"] + \" | \" + m[\"frequency\"]\n",
        "    return dict(zip(m[\"column\"], m[\"label\"]))\n",
        "\n",
        "def save_summary_small(rf, X, meta_map):\n",
        "    Xn = X.copy(); Xn.columns = [meta_map.get(c, c) for c in X.columns]\n",
        "    expl = shap.TreeExplainer(rf)\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    shap.summary_plot(expl.shap_values(Xn), Xn, show=False)\n",
        "    tmp = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
        "    plt.savefig(tmp.name, bbox_inches=\"tight\"); plt.close()\n",
        "    return tmp.name\n",
        "\n",
        "def small_waterfall_png(rf, X_row, meta_map):\n",
        "    expl = shap.TreeExplainer(rf)\n",
        "    sv   = expl.shap_values(X_row)[0]\n",
        "    names= [meta_map.get(c, c) for c in X_row.columns]\n",
        "    expln= shap.Explanation(values=sv, base_values=expl.expected_value,\n",
        "                            data=X_row.values[0], feature_names=names)\n",
        "    ax   = shap.plots.waterfall(expln, show=False)\n",
        "    fig  = ax.figure if hasattr(ax, \"figure\") else plt.gcf()\n",
        "    tmp  = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
        "    fig.savefig(tmp.name, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    return tmp.name\n",
        "\n",
        "# ───────── train / load (in-memory) ─────────\n",
        "def train_model(train_csv, meta_csv, state):\n",
        "    if train_csv is None:\n",
        "        return \"⚠️ Upload training CSV.\", None, {}\n",
        "    df = pd.read_csv(train_csv.name)\n",
        "    if \"client_name\" in df: df = df.drop(\"client_name\", axis=1)\n",
        "    if \"price_total\" not in df:\n",
        "        return \"`price_total` column missing.\", None, {}\n",
        "\n",
        "    X, y = df.drop(\"price_total\", axis=1).fillna(0), df[\"price_total\"]\n",
        "    Xt, Xv, yt, yv = train_test_split(X, y, test_size=.2, random_state=42)\n",
        "    rf = RandomForestRegressor(n_estimators=120, random_state=42).fit(Xt, yt)\n",
        "\n",
        "    mae  = mean_absolute_error(yt, rf.predict(Xt))\n",
        "    rmse = mean_squared_error(yv, rf.predict(Xv))**0.5\n",
        "    r2   = rf.score(Xv, yv)\n",
        "    msg  = f\"**MAE {mae:.1f} | RMSE {rmse:.1f} | R² {r2:.2f}**\"\n",
        "\n",
        "    meta_map = meta_map_from_csv(meta_csv)\n",
        "    summ_png = save_summary_small(rf, X, meta_map)\n",
        "    state[\"model\"], state[\"features\"], state[\"meta\"] = rf, X.columns.tolist(), meta_map\n",
        "    return msg, summ_png, state\n",
        "\n",
        "# ───────── prediction ──────────\n",
        "def predict(offer_csv, state):\n",
        "    if offer_csv is None or \"model\" not in state:\n",
        "        return pd.DataFrame(), gr.update(choices=[]), state\n",
        "    df = pd.read_csv(offer_csv.name).fillna(0).reset_index(drop=True)\n",
        "    rf, feats = state[\"model\"], state[\"features\"]\n",
        "    df[\"predicted_price\"] = np.round(rf.predict(df[feats]), 2)\n",
        "\n",
        "    df_view = df.copy()\n",
        "    for c in df_view.columns:\n",
        "        if c != \"client_name\":\n",
        "            df_view[c] = df_view[c].apply(lambda x: f\"{x:,.2f}\"\n",
        "                                          if c == \"predicted_price\"\n",
        "                                          else f\"{x:,}\")\n",
        "    names = df_view.get(\"client_name\",\n",
        "                        pd.Series([f\"Offer {i+1}\" for i in range(len(df_view))]))\n",
        "    choices = [f\"{i}: {n}\" for i, n in enumerate(names)]\n",
        "    state[\"Xoffers\"] = df[feats].to_dict()\n",
        "    return df_view, gr.update(choices=choices, value=None), state\n",
        "\n",
        "# ───────── individual SHAP ──────────\n",
        "def explain(row_choice, state):\n",
        "    if not row_choice or \"Xoffers\" not in state:\n",
        "        return None\n",
        "    idx = int(row_choice.split(\":\")[0])\n",
        "    X   = pd.DataFrame(state[\"Xoffers\"]).reset_index(drop=True)\n",
        "    return small_waterfall_png(state[\"model\"], X.iloc[[idx]], state[\"meta\"])\n",
        "\n",
        "# ─────────────── UI ──────────────\n",
        "with gr.Blocks(title=\"Logistics Price AI\") as demo:\n",
        "    gr.Markdown(\"## AI Logistics Price Prediction Model\")\n",
        "\n",
        "    app_state = gr.State({})          # lives for the session\n",
        "\n",
        "    # tab 1\n",
        "    with gr.Tab(\"Train / Load\"):\n",
        "        tr_csv  = gr.File(label=\"Training CSV\")\n",
        "        meta_csv= gr.File(label=\"Metadata catalog (optional)\")\n",
        "        tr_btn  = gr.Button(\"Train model\", variant=\"primary\")\n",
        "        tr_msg  = gr.Markdown()\n",
        "        tr_img  = gr.Image(type=\"filepath\")\n",
        "\n",
        "    # tab 2\n",
        "    with gr.Tab(\"Predict & Explain\"):\n",
        "        off_csv = gr.File(label=\"Offer(s) CSV\")\n",
        "        pr_btn  = gr.Button(\"Predict\", variant=\"primary\")\n",
        "        table   = gr.Dataframe()\n",
        "        dd      = gr.Dropdown(label=\"Pick offer row\")\n",
        "        sh_img  = gr.Image(type=\"filepath\")\n",
        "\n",
        "    # wiring\n",
        "    tr_btn.click(train_model, [tr_csv, meta_csv, app_state],\n",
        "                 [tr_msg, tr_img, app_state])\n",
        "\n",
        "    pr_btn.click(predict, [off_csv, app_state],\n",
        "                 [table, dd, app_state])\n",
        "\n",
        "    dd.change(explain, [dd, app_state], sh_img)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "7nkMwOatd-O6",
        "outputId": "dc3fb645-9c55-49ec-8141-e479f9ad75f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://3f2f73270f2c326832.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3f2f73270f2c326832.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://3f2f73270f2c326832.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}